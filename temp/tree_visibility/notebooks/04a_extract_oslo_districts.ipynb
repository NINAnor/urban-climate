{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caclulate tree visibility statistics per district\n",
    "\n",
    "[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ac-willeke/urban-climate/blob/main/notebooks/01_FROST_extract_climate_data.ipynb) [![github](https://img.shields.io/badge/GitHub-View%20on%20GitHub-blue?logo=github)](https://github.com/ac-willeke/)\n",
    "\n",
    "**Author**: Willeke A'Campo\n",
    "\n",
    "**Description:** This notebooks shows how to calculate the Ecosystem Service statistics for tree visibility and impact per district using DuckDB. The results are stored in a new table in the database and exported to GeoJSON.\n",
    "\n",
    "**Documentation:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkb import loads\n",
    "import pyarrow\n",
    "import os\n",
    "import leafmap\n",
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# set temp dir to network drivve to avoid disk space issues\n",
    "os.environ['TMPDIR'] = r\"/home/NINA.NO/willeke.acampo/Mounts/P-Prosjekter2/152022_itree_eco_ifront_synliggjore_trars_rolle_i_okosyst/TEMP\"\n",
    "\n",
    "# TODO move to kedro pipeline\n",
    "municipality = \"oslo\"\n",
    "TEMP_DIR = os.environ['TMPDIR']\n",
    "raw_dir = os.path.join(TEMP_DIR, \"oslo\", \"01_raw\")\n",
    "interim_dir = os.path.join(TEMP_DIR, \"oslo\", \"02_intermediate\")\n",
    "reporting_dir = os.path.join(TEMP_DIR, \"oslo\", \"08_reporting\")\n",
    "\n",
    "\n",
    "# Define the table names\n",
    "file_names = [\n",
    "    f\"{municipality}_study_area\", \n",
    "    f\"{municipality}_districts\",\n",
    "    f\"{municipality}_bldg\",\n",
    "    f\"{municipality}_res_bldg\",\n",
    "    f\"{municipality}_green_space\",\n",
    "    f\"{municipality}_open_space\",\n",
    "    f\"{municipality}_public_open_space\",\n",
    "    f\"{municipality}_private_open_space\",\n",
    "    f\"{municipality}_tree_crowns\"\n",
    "    ]\n",
    "\n",
    "table_names = [\n",
    "    \"study_area\", \"districts\", \"bldg\", \"res_bldg\", \"green_space\",\n",
    "    \"open_space\", \"public_open_space\", \"private_open_space\", \"tree_crowns\"\n",
    "    ]\n",
    "\n",
    "district_geojson = os.path.join(interim_dir, f\"{municipality}_districts.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data conversion | GeoJSON to GeoParquet   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parquet_dict\n",
    "parquet_dict = {\n",
    "    name: os.path.join(interim_dir, f\"{name}.parquet\") \n",
    "    for name in file_names}\n",
    "\n",
    "# Check if the parquet files exist, if not convert  to parquet\n",
    "for key in parquet_dict.keys():\n",
    "    if os.path.exists(parquet_dict[key]):\n",
    "        # check crs\n",
    "        gdf = gpd.read_parquet(parquet_dict[key])\n",
    "        \n",
    "        # remove areas smaller than 1m2 for all files \n",
    "        if key != \"tree_crowns\":\n",
    "            print(f\"Removing areas smaller than 1 m2 from {key}\")\n",
    "            len_before = len(gdf)\n",
    "            gdf = gdf[gdf.area > 1]\n",
    "            len_after = len(gdf)\n",
    "            print(f\"Removed {len_before - len_after} rows\")\n",
    "        \n",
    "        print(f\"CRS of {key} is {gdf.crs}\")\n",
    "        # if epsg is not 25832, reproject and overwrite parquet\n",
    "        if gdf.crs.to_epsg() != 25832:\n",
    "            print(f\"Reprojecting {key} to epsg:25832\")\n",
    "            gdf = gdf.to_crs(epsg=25832)\n",
    "            gdf.to_parquet(\n",
    "                path = interim_dir + \"/\" + key + \".parquet\",\n",
    "                index = None, \n",
    "                compression = \"snappy\"\n",
    "            )\n",
    "        # if geosjon does not exist in reporting dir, export\n",
    "        if not os.path.exists(os.path.join(reporting_dir, f\"{key}.geojson\")):\n",
    "            print(f\"Exporting {key} to geojson\")\n",
    "            #gdf.to_file(os.path.join(reporting_dir, f\"{key}.geojson\"), driver=\"GeoJSON\")    \n",
    "    else:\n",
    "        # convert all .geojson and .shp files to .parquet\n",
    "        for file in os.listdir(raw_dir):\n",
    "            if file.endswith(\".geojson\") or file.endswith(\".shp\"):\n",
    "                print(f\"Converting {file} to parquet\")\n",
    "                gdf = gpd.read_file(os.path.join(raw_dir, file))\n",
    "                gdf.to_parquet(\n",
    "                    path = interim_dir + \"/\" + file.split(\".\")[0] + \".parquet\",\n",
    "                    index = None, \n",
    "                    compression = \"snappy\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load District Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the district data\n",
    "districts = gpd.read_file(os.path.join(raw_dir, f\"{municipality}_districts.geojson\"))\n",
    "districts = districts.to_crs(epsg=25832)\n",
    "\n",
    "# export a parquet file for each district (delomrade)\n",
    "district_list = districts['delomradenummer'].unique()\n",
    "district_list = sorted(district_list)\n",
    "\n",
    "# print list of unique delomrade numbers \n",
    "print(f\"Number of districts: {len(district_list)} \\n\")\n",
    "print(f\"Districts: {district_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get district list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function \n",
    "def export_by_district(gdf_dict, file_names, district_list, col_district):\n",
    "    \n",
    "    for gdf, file_name, number in zip(gdf_dict, file_names, district_list):\n",
    "        print(f\"Exporting {file_name} for district {number}\")\n",
    "        gdf = gdf[gdf[col_district] == number]\n",
    "        display(gdf)\n",
    "        \n",
    "        gdf.to_parquet(\n",
    "            path = os.path.join(interim_dir,\"parquet\", file_name + \".parquet\")\n",
    "            index = None, \n",
    "            compression = \"snappy\"\n",
    "        )\n",
    "        \n",
    "        # save to shp\n",
    "        gdf.to_file(\n",
    "            os.path.join(interim_dir, \"shp\", file_name + \".shp\"),\n",
    "            driver='ESRI Shapefile'\n",
    "            )\n",
    "    \n",
    "    for number in district_list:\n",
    "        print(f\"Exporting {number}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in district_list:\n",
    "    district_number = n\n",
    "    #print(f\"District number: {district_number}\")\n",
    "    district = districts.loc[districts['delomradenummer'] == district_number]\n",
    "    \n",
    "    # if not None display \n",
    "    if district is not None:\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"District {n} is None\")\n",
    "        \n",
    "    district.to_parquet(\n",
    "        path = interim_dir + \"/\" + f\"district_{district_number}\" + \".parquet\",\n",
    "        index = None, \n",
    "        compression = \"snappy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all other tabels and split based on DISTRICT NUMBER value (not geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes that all tables have an attribute field populated with the district number! \n",
    "# load all data to \n",
    "for file in os.listdir(interim_dir):\n",
    "    if file.endswith(\".geojson\") or file.endswith(\".shp\"):\n",
    "        gdf = gpd.read_file(os.path.join(raw_dir, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all other tables and SPATIALLY split by district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL AUTOMATICALLY\n",
    "raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "# Rest of your code...\n",
    "\n",
    "for district_number in district_list:\n",
    "    # load district {district_number} from parquet\n",
    "    con = duckdb.connect(database=\":memory:\", read_only=False)\n",
    "    con.install_extension(\"spatial\")\n",
    "    con.load_extension(\"spatial\")\n",
    "\n",
    "    # create a duckdb table for the district\n",
    "    district_path = os.path.join(interim_dir, f\"district_{district_number}.parquet\")\n",
    "    print(f\"District number: {district_number}\")\n",
    "\n",
    "    con.execute(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE district_{district_number}\n",
    "        AS SELECT *, ST_GeomFromWKB(geometry) \n",
    "        FROM parquet_scan('{district_path}')\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Load all other tables\n",
    "    for key,table in zip(parquet_dict.keys(), table_names):\n",
    "        if table != 'districts':\n",
    "            con.execute(\n",
    "                f\"\"\"\n",
    "                CREATE TABLE {table} \n",
    "                AS SELECT *, ST_GeomFromWKB(geometry) \n",
    "                FROM parquet_scan('{parquet_dict[key]}')\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "    # Spatially clip all other tables to geometry of 'district_{district_number}' and create a new table {table}_{district_number} and export it to {table}_{district_number}.parquet\n",
    "    for table in table_names:\n",
    "        if table != 'districts':\n",
    "            con.execute(\n",
    "                f\"\"\"\n",
    "                CREATE TABLE {table}_{district_number} \n",
    "                AS SELECT *, ST_GeomFromWKB(geometry) as geometry\n",
    "                FROM {table} \n",
    "                WHERE ST_Intersects(ST_GeomFromWKB(geometry), (SELECT ST_GeomFromWKB(geometry) FROM district_{district_number}))\n",
    "                \"\"\"\n",
    "            )\n",
    "            con.execute(\n",
    "                f\"\"\"\n",
    "                COPY (SELECT * FROM {table}_{district_number}) TO '{interim_dir}/{table}_{district_number}.parquet' (FORMAT 'parquet')\n",
    "                \"\"\"\n",
    "            )\n",
    "            \n",
    "    con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
